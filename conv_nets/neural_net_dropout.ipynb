{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "bfc80cf6-6e80-4671-ae92-7fb40120ad6b",
   "metadata": {},
   "source": [
    "# When/How is Dropout applied\n",
    "## Is it per forward pass(training example), per batch or per epoch\n",
    "Several forward passes(i.e one forward pass = 1 training example) make one batch. Several batches make one epoch. \n",
    "\n",
    "In PyTorch, a unique dropout mask (where elements are zeroed out) is applied to the input tensor during each forward pass during training.\n",
    "\n",
    "Effectively creating a different network architecture **for each forward pass. i.e for every training example** it is a unique dropout(the percentage dropout will be the same. But which neurons are turned on/off are unique to each forward pass = unique to each training example)\n",
    "The same neurons remain turned off until the backpropagation and weight update. \n",
    "\n",
    "For the next set of {forward-pass, backpropagation, weightupdate} another set of neurons are turned on/off . \n",
    "\n",
    "Here's a more detailed explanation:\n",
    "\n",
    "### Dropout Purpose:\n",
    "Dropout is a regularization technique used to prevent overfitting in neural networks. It works by randomly setting a fraction of input units (neurons) to zero during each forward pass. \n",
    "\n",
    "### Unique Mask:\n",
    "For each forward pass during training, a new random mask is generated, determining which neurons will be \"dropped out\" (set to zero). This means that the network effectively trains on different sub-networks in each iteration, which helps it to generalize better.\n",
    "\n",
    "### During Training vs Inference:\n",
    "Dropout is only applied during the training phase. During evaluation (inference), the dropout layer simply passes the input through without any zeroing, ensuring that the model's performance is evaluated on the full network. \n",
    "PyTorch Implementation:\n",
    "In PyTorch, you can implement dropout using the torch.nn.Dropout module. You specify the probability p of an element being zeroed out, with a default value of 0.5. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d9a88c24-6d0f-4e31-bce7-9d6667c067f0",
   "metadata": {},
   "source": [
    "## Example\n",
    "To implement dropout in PyTorch and verify the applied percentage, define a nn.Dropout layer with a specified probability (e.g., p=0.5), then use it within your model's forward method, and finally, check the percentage of elements zeroed out in the output tensor during training. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8953d096-6cb3-4e29-a2ea-e313e30b1af9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1. Define the Dropout Layer:\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "\n",
    "# Define the dropout probability (e.g., 50%)\n",
    "dropout_prob = 0.8\n",
    "\n",
    "# Create a dropout layer\n",
    "dropout_layer = nn.Dropout(p=dropout_prob)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d56074ed-055e-445a-b03c-133ff4c3d81e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2. Incorporate into your Model:\n",
    "## KSW-TODO: Note it is silly to define dropout at the end of the network. I've just done it to demonstrate dropout\n",
    "## Come up with sth better\n",
    "## TODO: how do you check the dropouts of the individual layers ?? When you call model you can only check the final output\n",
    "\n",
    "class MyModel(nn.Module):\n",
    "    def __init__(self, input_size, hidden_size, output_size):\n",
    "        super(MyModel, self).__init__()\n",
    "        self.fc1 = nn.Linear(input_size, hidden_size)\n",
    "        self.dropout1 = nn.Dropout(p=dropout_prob) # Define dropout here\n",
    "        self.fc2 = nn.Linear(hidden_size, output_size)\n",
    "        self.dropout2 = nn.Dropout(p=dropout_prob) # Define dropout here\n",
    "        \n",
    "    def forward(self, x):\n",
    "        x = torch.relu(self.fc1(x))\n",
    "        x = self.dropout1(x) # Apply dropout\n",
    "        x = self.fc2(x)\n",
    "        x = self.dropout2(x) # Apply dropout\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e5b2e0c7-322e-4ec3-8fff-e88fb5677042",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 3. Verify Dropout Application during training\n",
    "# Example usage\n",
    "input_size = 10\n",
    "hidden_size = 20\n",
    "output_size = 5\n",
    "model = MyModel(input_size, hidden_size, output_size)\n",
    "\n",
    "print(\"Checking dropout rates during model TRAINING\")\n",
    "# Perform a forward pass\n",
    "model.train()\n",
    "for i in range(0,10):\n",
    "    # Create a dummy input\n",
    "    input_tensor = torch.randn(1, input_size)\n",
    "    output_tensor = model(input_tensor)\n",
    "    \n",
    "    # Check the percentage of zeroed elements\n",
    "    print(f\"i={i}\")\n",
    "    print(f\"Dropout Probability: {dropout_prob}\")\n",
    "    print(f\"Percentage of zeroed elements: {(1-(torch.count_nonzero(output_tensor) / output_tensor.numel())) * 100:.2f}%\")\n",
    "    print(\"----------------------\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9dd8fa3e-e2e6-444c-93aa-4e50221e6ace",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 3. Verify Dropout Application during evaluation\n",
    "# Example usage\n",
    "input_size = 10\n",
    "hidden_size = 20\n",
    "output_size = 5\n",
    "model = MyModel(input_size, hidden_size, output_size)\n",
    "\n",
    "print(\"Checking dropout rates during model EVALUATION\")\n",
    "# Perform a forward pass\n",
    "model.eval()\n",
    "for i in range(0,10):\n",
    "    # Create a dummy input\n",
    "    input_tensor = torch.randn(1, input_size)\n",
    "    output_tensor = model(input_tensor)\n",
    "    \n",
    "    # Check the percentage of zeroed elements\n",
    "    print(f\"i={i}\")\n",
    "    print(f\"Dropout Probability: {dropout_prob}\")\n",
    "    print(f\"Percentage of zeroed elements: {(1-(torch.count_nonzero(output_tensor) / output_tensor.numel())) * 100:.2f}%\")\n",
    "    print(\"----------------------\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
