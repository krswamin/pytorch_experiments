{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d19d5926-fcac-4f7a-82a2-9d809fb16905",
   "metadata": {},
   "source": [
    "# Linear Regression with Model , Loss and Optimizer\n",
    "Note: in PyTorch, when you call an instance of a nn.Module, it always internally calls the forward method. \\\n",
    "\\\n",
    "This behavior is due to the __call__ method defined within the nn.Module class. When you invoke a nn.Module object like a function (e.g., model(input)), the __call__ method is executed, which in turn calls the forward method with the provided input.\\\n",
    "\\\n",
    "It's important to note that you should not directly call the forward method yourself (e.g., model.forward(input)). Calling the module instance ensures that all the necessary hooks and mechanisms within PyTorch are properly executed, including pre-forward hooks, the actual forward pass, and post-forward hooks. Directly calling forward bypasses these mechanisms, potentially leading to unexpected behavior, especially when using features like hooks or when working with models in training mode."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a07009ad-0c4b-4c63-8248-7f111ae61f6b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "\n",
    "# Linear Regression \n",
    "# f = w*x +b \n",
    "\n",
    "# 0) Training samples, watch the shape\n",
    "X = torch.tensor([[1],[2],[3],[4], [5],[6],[7],[8]], dtype = torch.float32)\n",
    "Y = torch.tensor([[2],[4],[6],[8],[10],[12],[14],[16]], dtype = torch.float32)\n",
    "print(\"X.shape=\", X.shape)\n",
    "\n",
    "n_samples , n_features = X.shape\n",
    "print(f'n_samples = {n_samples}, n_features = {n_features}')\n",
    "\n",
    "# 0) Create a test sample\n",
    "X_test = torch.tensor([5], dtype = torch.float32)\n",
    "print(\"X_test.shape:\", X_test.shape, \",X_test=\", X_test)\n",
    "\n",
    "#1) Design the model. then model has to implement the forward pass.\n",
    "# You can use a pytroch built-in-model such as \n",
    "# model = nn.Linear(input_size, output_size)\n",
    "# If you are defining your own model, it typically inherits from the nn.Module\n",
    "class LinearRegression(nn.Module):\n",
    "    # Define the layers\n",
    "    def __init__(self, input_dim, output_dim):\n",
    "        super(LinearRegression, self).__init__()\n",
    "        # define different layers\n",
    "        self.lin = nn.Linear(input_dim, output_dim)\n",
    "    \n",
    "    # Apply the layers\n",
    "    def forward(self, x):\n",
    "        return self.lin(x)\n",
    "\n",
    "\n",
    "\n",
    "# 2) Create an instance of the class\n",
    "input_size, output_size = n_features, n_features\n",
    "model = LinearRegression(input_size, output_size)\n",
    "print(f'Prediction before training: f({X_test.item()}) = {model(X_test).item():.3f}')\n",
    "\n",
    "#3) Define the loss and optimizer\n",
    "n_epochs = 100\n",
    "learning_rate = 0.01\n",
    "loss = nn.MSELoss()\n",
    "# SGD is stochastic gradient descent\n",
    "optimizer = torch.optim.SGD(model.parameters(), lr= learning_rate)\n",
    "\n",
    "#4) Define the training loop\n",
    "for epoch in range(n_epochs):\n",
    "    # predict = forward pass with our model\n",
    "    y_predicted = model(X)\n",
    "\n",
    "    #loss\n",
    "    l = loss(Y, y_predicted)\n",
    "\n",
    "    # calculate the gradients : backward pass\n",
    "    l.backward()\n",
    "\n",
    "    # update weights \n",
    "    # model.update ??\n",
    "    optimizer.step()\n",
    "\n",
    "    # after updating the weights, zero the gradients before the next iteration\n",
    "    optimizer.zero_grad()\n",
    "\n",
    "    if (epoch+1) % 10 ==0:\n",
    "        w,b = model.parameters() # unpack parameters\n",
    "        print(f'epoch {epoch+1}: w = {w[0][0].item():.3f}, loss = {l.item():.3f}')\n",
    "\n",
    "\n",
    "print(f'Prediction after training: f({X_test.item()}) = {model(X_test).item():.3f}')\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
